# Clasificaci贸n Multiclase y Optimizaci贸n de Modelos en el Dataset "20 Newsgroups"

Este repositorio contiene ejercicios y experimentos sobre clasificaci贸n multiclase, aplicados al dataset "20 Newsgroups". Se presentan las m茅tricas utilizadas en este tipo de problemas y una comparaci贸n de varios clasificadores entrenados y optimizados para lograr el mejor rendimiento posible.

<br>

## Ejercicio 1: Interpretaci贸n de m茅tricas en clasificaci贸n multiclase

En la clasificaci贸n multiclase, m茅tricas como **Accuracy**, **Precision**, **Recall** y **F1-Score** se interpretan con ciertas adaptaciones para manejar m煤ltiples clases. En este repositorio, se discuten:

- **Accuracy**: Proporci贸n global de predicciones correctas.
- **Precision, Recall y F1-Score por clase**: Evaluaci贸n espec铆fica para cada clase.
- **Promedios globales (Micro, Macro, Weighted)**: Resumen general de m茅tricas para evaluar el modelo globalmente.

El enfoque empleado incluye:
1. Reportar m茅tricas por clase.
2. Proporcionar promedios globales utilizando estrategias como micro, macro y weighted.

Consulta la documentaci贸n en el archivo para m谩s detalles.

<br>

## Ejercicio 2: Clasificaci贸n del dataset "20 Newsgroups"

### Descripci贸n del problema

Se clasifica el dataset "20 Newsgroups" utilizando m煤ltiples clasificadores:
- **Multinomial Naive Bayes**
- **Regresi贸n Log铆stica**
- **LinearSVC**
- **Perceptron**

Se realizan ajustes de hiperpar谩metros y optimizaci贸n de cada modelo con el objetivo de encontrar la mejor soluci贸n. El rendimiento se eval煤a en t茅rminos de m茅tricas est谩ndar y visualizaciones de resultados.

### Dataset

- **Fuente**: `sklearn.datasets.fetch_20newsgroups`
- **Clases**: 20 categor铆as de noticias.
- **Tama帽o del conjunto de datos**: 
  - Entrenamiento: ~11,000 documentos.
  - Prueba: ~7,500 documentos.

<br>

## Resultados

### Comparaci贸n de modelos

| Modelo               | Accuracy | Principales Hiperpar谩metros                          |
|----------------------|----------|-----------------------------------------------------|
| **LinearSVC**        | 0.823    | `C=0.01, loss='squared_hinge', max_iter=15000`     |
| **LogisticRegression** | 0.803 | `C=1, penalty='l2', solver='lbfgs'`                 |
| **MultinomialNB**    | 0.792    | `alpha=0.0001, fit_prior=True`                     |
| **Perceptron**       | 0.741    | `alpha=0.0001`                                     |

### Mejor soluci贸n: LinearSVC
- **Accuracy**: 82.3%
- **Principales m茅tricas por clase**:  
  - Promedio ponderado de F1-Score: 0.822.
  - Mejores clases: 
    - *rec.motorcycles*: F1-Score = 0.942.
    - *rec.sport.hockey*: F1-Score = 0.944.
  - Clases m谩s dif铆ciles: 
    - *talk.religion.misc*: F1-Score = 0.650.
    - *talk.politics.misc*: F1-Score = 0.667.

<br>

## Visualizaciones

El repositorio incluye scripts para generar gr谩ficos de **Precision**, **Recall**, **F1-Score** y **Support** para cada clase. Los gr谩ficos proporcionan una visi贸n clara del rendimiento del modelo por categor铆a y a nivel global.

<br>

## Requisitos

- Python >= 3.7
- Librer铆as principales:
  - `scikit-learn`
  - `pandas`
  - `matplotlib`

--- 

隆Espero que sea 煤til! Si necesitas ajustes, no dudes en ped铆rmelo. 
